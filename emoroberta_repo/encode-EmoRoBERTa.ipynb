{"cells":[{"cell_type":"markdown","metadata":{"id":"53N4k0pj_9qL"},"source":["# Preparation for Colab\n","\n","Make sure you're running a GPU runtime; if not, select \"GPU\" as the hardware accelerator in Runtime > Change Runtime Type in the menu. The next cells will install the `clip` package and its dependencies, and check if PyTorch 1.7.1 or later is installed."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104403,"status":"ok","timestamp":1712153718400,"user":{"displayName":"Alex Terentowicz","userId":"10722644937446686009"},"user_tz":-120},"id":"0BpdJkdBssk9","outputId":"cf422b63-9319-44e7-9f42-fde2450a3bac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ftfy\n","  Using cached ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n","Collecting regex\n","  Downloading regex-2024.7.24-cp39-cp39-win_amd64.whl.metadata (41 kB)\n","Collecting tqdm\n","  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in .\\.venv\\lib\\site-packages (from ftfy) (0.2.13)\n","Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n","Using cached ftfy-6.2.3-py3-none-any.whl (43 kB)\n","Downloading regex-2024.7.24-cp39-cp39-win_amd64.whl (269 kB)\n","Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n","Installing collected packages: tqdm, regex, ftfy\n","Successfully installed ftfy-6.2.3 regex-2024.7.24 tqdm-4.66.5\n","Looking in indexes: https://download.pytorch.org/whl/cu118\n","Collecting torch\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.4.0%2Bcu118-cp39-cp39-win_amd64.whl (2692.7 MB)\n","     ---------------------------------------- 0.0/2.7 GB ? eta -:--:--\n","     ---------------------------------------- 0.0/2.7 GB 101.8 MB/s eta 0:00:27\n","      --------------------------------------- 0.0/2.7 GB 105.2 MB/s eta 0:00:26\n","      --------------------------------------- 0.1/2.7 GB 105.5 MB/s eta 0:00:25\n","     - -------------------------------------- 0.1/2.7 GB 104.8 MB/s eta 0:00:25\n","     - -------------------------------------- 0.1/2.7 GB 104.2 MB/s eta 0:00:25\n","     - -------------------------------------- 0.1/2.7 GB 103.4 MB/s eta 0:00:25\n","     -- ------------------------------------- 0.1/2.7 GB 103.6 MB/s eta 0:00:25\n","     -- ------------------------------------- 0.2/2.7 GB 105.2 MB/s eta 0:00:24\n","     -- ------------------------------------- 0.2/2.7 GB 105.1 MB/s eta 0:00:24\n","     --- ------------------------------------ 0.2/2.7 GB 103.9 MB/s eta 0:00:24\n","     --- ------------------------------------ 0.2/2.7 GB 104.4 MB/s eta 0:00:24\n","     --- ------------------------------------ 0.3/2.7 GB 103.8 MB/s eta 0:00:24\n","     ---- ----------------------------------- 0.3/2.7 GB 104.1 MB/s eta 0:00:24\n","     ---- ----------------------------------- 0.3/2.7 GB 104.8 MB/s eta 0:00:23\n","     ---- ----------------------------------- 0.3/2.7 GB 105.4 MB/s eta 0:00:23\n","     ----- ---------------------------------- 0.3/2.7 GB 105.4 MB/s eta 0:00:23\n","     ----- ---------------------------------- 0.4/2.7 GB 105.4 MB/s eta 0:00:23\n","     ----- ---------------------------------- 0.4/2.7 GB 105.4 MB/s eta 0:00:22\n","     ------ --------------------------------- 0.4/2.7 GB 105.4 MB/s eta 0:00:22\n","     ------ --------------------------------- 0.4/2.7 GB 104.8 MB/s eta 0:00:22\n","     ------ --------------------------------- 0.5/2.7 GB 104.8 MB/s eta 0:00:22\n","     ------- -------------------------------- 0.5/2.7 GB 104.8 MB/s eta 0:00:22\n","     ------- -------------------------------- 0.5/2.7 GB 105.4 MB/s eta 0:00:21\n","     ------- -------------------------------- 0.5/2.7 GB 106.1 MB/s eta 0:00:21\n","     -------- ------------------------------- 0.5/2.7 GB 105.4 MB/s eta 0:00:21\n","     -------- ------------------------------- 0.6/2.7 GB 104.1 MB/s eta 0:00:21\n","     -------- ------------------------------- 0.6/2.7 GB 102.8 MB/s eta 0:00:21\n","     -------- ------------------------------- 0.6/2.7 GB 102.8 MB/s eta 0:00:21\n","     --------- ------------------------------ 0.6/2.7 GB 103.5 MB/s eta 0:00:20\n","     --------- ------------------------------ 0.6/2.7 GB 103.5 MB/s eta 0:00:20\n","     --------- ------------------------------ 0.7/2.7 GB 103.5 MB/s eta 0:00:20\n","     ---------- ----------------------------- 0.7/2.7 GB 102.8 MB/s eta 0:00:20\n","     ---------- ----------------------------- 0.7/2.7 GB 104.1 MB/s eta 0:00:19\n","     ---------- ----------------------------- 0.7/2.7 GB 104.1 MB/s eta 0:00:19\n","     ----------- ---------------------------- 0.8/2.7 GB 104.1 MB/s eta 0:00:19\n","     ----------- ---------------------------- 0.8/2.7 GB 105.4 MB/s eta 0:00:19\n","     ----------- ---------------------------- 0.8/2.7 GB 107.5 MB/s eta 0:00:18\n","     ------------ --------------------------- 0.8/2.7 GB 106.1 MB/s eta 0:00:18\n","     ------------ --------------------------- 0.8/2.7 GB 106.8 MB/s eta 0:00:18\n","     ------------ --------------------------- 0.9/2.7 GB 107.5 MB/s eta 0:00:17\n","     ------------- -------------------------- 0.9/2.7 GB 108.2 MB/s eta 0:00:17\n","     ------------- -------------------------- 0.9/2.7 GB 107.4 MB/s eta 0:00:17\n","     ------------- -------------------------- 0.9/2.7 GB 108.1 MB/s eta 0:00:17\n","     -------------- ------------------------- 1.0/2.7 GB 108.8 MB/s eta 0:00:16\n","     -------------- ------------------------- 1.0/2.7 GB 108.1 MB/s eta 0:00:16\n","     -------------- ------------------------- 1.0/2.7 GB 109.5 MB/s eta 0:00:16\n","     --------------- ------------------------ 1.0/2.7 GB 109.5 MB/s eta 0:00:16\n","     --------------- ------------------------ 1.0/2.7 GB 108.1 MB/s eta 0:00:16\n","     --------------- ------------------------ 1.1/2.7 GB 108.8 MB/s eta 0:00:15\n","     --------------- ------------------------ 1.1/2.7 GB 99.2 MB/s eta 0:00:17\n","     ---------------- ----------------------- 1.1/2.7 GB 100.3 MB/s eta 0:00:16\n","     ---------------- ----------------------- 1.1/2.7 GB 100.4 MB/s eta 0:00:16\n","     ---------------- ----------------------- 1.1/2.7 GB 99.8 MB/s eta 0:00:16\n","     ----------------- ---------------------- 1.2/2.7 GB 101.0 MB/s eta 0:00:16\n","     ----------------- ---------------------- 1.2/2.7 GB 101.6 MB/s eta 0:00:15\n","     ----------------- ---------------------- 1.2/2.7 GB 100.4 MB/s eta 0:00:15\n","     ------------------ --------------------- 1.2/2.7 GB 100.4 MB/s eta 0:00:15\n","     ------------------ --------------------- 1.3/2.7 GB 100.4 MB/s eta 0:00:15\n","     ------------------- -------------------- 1.3/2.7 GB 100.3 MB/s eta 0:00:15\n","     ------------------- -------------------- 1.3/2.7 GB 99.8 MB/s eta 0:00:14\n","     ------------------- -------------------- 1.3/2.7 GB 110.3 MB/s eta 0:00:13\n","     -------------------- ------------------- 1.3/2.7 GB 111.0 MB/s eta 0:00:13\n","     -------------------- ------------------- 1.4/2.7 GB 111.0 MB/s eta 0:00:12\n","     -------------------- ------------------- 1.4/2.7 GB 111.0 MB/s eta 0:00:12\n","     --------------------- ------------------ 1.4/2.7 GB 110.3 MB/s eta 0:00:12\n","     --------------------- ------------------ 1.4/2.7 GB 111.8 MB/s eta 0:00:12\n","     --------------------- ------------------ 1.5/2.7 GB 112.5 MB/s eta 0:00:11\n","     ---------------------- ----------------- 1.5/2.7 GB 114.0 MB/s eta 0:00:11\n","     ---------------------- ----------------- 1.5/2.7 GB 114.0 MB/s eta 0:00:11\n","     ---------------------- ----------------- 1.5/2.7 GB 114.1 MB/s eta 0:00:11\n","     ----------------------- ---------------- 1.6/2.7 GB 114.8 MB/s eta 0:00:10\n","     ----------------------- ---------------- 1.6/2.7 GB 114.0 MB/s eta 0:00:10\n","     ----------------------- ---------------- 1.6/2.7 GB 113.2 MB/s eta 0:00:10\n","     ------------------------ --------------- 1.6/2.7 GB 112.4 MB/s eta 0:00:10\n","     ------------------------ --------------- 1.6/2.7 GB 111.7 MB/s eta 0:00:10\n","     ------------------------ --------------- 1.7/2.7 GB 111.0 MB/s eta 0:00:10\n","     ------------------------- -------------- 1.7/2.7 GB 111.7 MB/s eta 0:00:09\n","     ------------------------- -------------- 1.7/2.7 GB 111.0 MB/s eta 0:00:09\n","     ------------------------- -------------- 1.7/2.7 GB 109.6 MB/s eta 0:00:09\n","     -------------------------- ------------- 1.8/2.7 GB 108.1 MB/s eta 0:00:09\n","     -------------------------- ------------- 1.8/2.7 GB 108.1 MB/s eta 0:00:09\n","     -------------------------- ------------- 1.8/2.7 GB 108.2 MB/s eta 0:00:09\n","     --------------------------- ------------ 1.8/2.7 GB 107.4 MB/s eta 0:00:09\n","     --------------------------- ------------ 1.9/2.7 GB 107.4 MB/s eta 0:00:08\n","     --------------------------- ------------ 1.9/2.7 GB 108.8 MB/s eta 0:00:08\n","     ---------------------------- ----------- 1.9/2.7 GB 109.5 MB/s eta 0:00:08\n","     ---------------------------- ----------- 1.9/2.7 GB 111.0 MB/s eta 0:00:07\n","     ---------------------------- ----------- 1.9/2.7 GB 111.7 MB/s eta 0:00:07\n","     ----------------------------- ---------- 2.0/2.7 GB 112.5 MB/s eta 0:00:07\n","     ----------------------------- ---------- 2.0/2.7 GB 113.3 MB/s eta 0:00:07\n","     ----------------------------- ---------- 2.0/2.7 GB 112.5 MB/s eta 0:00:07\n","     ------------------------------ --------- 2.0/2.7 GB 112.4 MB/s eta 0:00:06\n","     ------------------------------ --------- 2.1/2.7 GB 113.2 MB/s eta 0:00:06\n","     ------------------------------- -------- 2.1/2.7 GB 112.5 MB/s eta 0:00:06\n","     ------------------------------- -------- 2.1/2.7 GB 111.0 MB/s eta 0:00:06\n","     ------------------------------- -------- 2.1/2.7 GB 111.0 MB/s eta 0:00:06\n","     ------------------------------- -------- 2.2/2.7 GB 108.8 MB/s eta 0:00:05\n","     -------------------------------- ------- 2.2/2.7 GB 108.1 MB/s eta 0:00:05\n","     -------------------------------- ------- 2.2/2.7 GB 103.5 MB/s eta 0:00:05\n","     -------------------------------- ------- 2.2/2.7 GB 98.0 MB/s eta 0:00:06\n","     -------------------------------- ------- 2.2/2.7 GB 98.6 MB/s eta 0:00:05\n","     --------------------------------- ------ 2.2/2.7 GB 97.5 MB/s eta 0:00:05\n","     --------------------------------- ------ 2.3/2.7 GB 96.9 MB/s eta 0:00:05\n","     --------------------------------- ------ 2.3/2.7 GB 96.3 MB/s eta 0:00:05\n","     ---------------------------------- ----- 2.3/2.7 GB 95.8 MB/s eta 0:00:05\n","     ---------------------------------- ----- 2.3/2.7 GB 95.2 MB/s eta 0:00:04\n","     ---------------------------------- ----- 2.3/2.7 GB 94.7 MB/s eta 0:00:04\n","     ----------------------------------- ---- 2.4/2.7 GB 96.3 MB/s eta 0:00:04\n","     ----------------------------------- ---- 2.4/2.7 GB 96.9 MB/s eta 0:00:04\n","     ----------------------------------- ---- 2.4/2.7 GB 96.9 MB/s eta 0:00:03\n","     ------------------------------------ --- 2.4/2.7 GB 104.8 MB/s eta 0:00:03\n","     ------------------------------------ --- 2.5/2.7 GB 105.4 MB/s eta 0:00:03\n","     ------------------------------------ --- 2.5/2.7 GB 104.8 MB/s eta 0:00:02\n","     ------------------------------------- -- 2.5/2.7 GB 105.4 MB/s eta 0:00:02\n","     ------------------------------------- -- 2.5/2.7 GB 106.1 MB/s eta 0:00:02\n","     ------------------------------------- -- 2.5/2.7 GB 106.1 MB/s eta 0:00:02\n","     -------------------------------------- - 2.6/2.7 GB 106.7 MB/s eta 0:00:02\n","     -------------------------------------- - 2.6/2.7 GB 106.8 MB/s eta 0:00:01\n","     -------------------------------------- - 2.6/2.7 GB 106.8 MB/s eta 0:00:01\n","     ---------------------------------------  2.6/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 105.4 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------  2.7/2.7 GB 106.1 MB/s eta 0:00:01\n","     ---------------------------------------- 2.7/2.7 GB 44.2 MB/s eta 0:00:00\n","Collecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp39-cp39-win_amd64.whl (5.0 MB)\n","     ---------------------------------------- 0.0/5.0 MB ? eta -:--:--\n","     ---------------------------------------- 5.0/5.0 MB 50.7 MB/s eta 0:00:00\n","Collecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp39-cp39-win_amd64.whl (4.0 MB)\n","     ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n","     ---------------------------------------- 4.0/4.0 MB 40.3 MB/s eta 0:00:00\n","Collecting filelock (from torch)\n","  Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n","Requirement already satisfied: typing-extensions>=4.8.0 in .\\.venv\\lib\\site-packages (from torch) (4.12.2)\n","Collecting sympy (from torch)\n","  Using cached https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n","Collecting networkx (from torch)\n","  Using cached https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n","Collecting jinja2 (from torch)\n","  Using cached https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)\n","Collecting fsspec (from torch)\n","  Using cached https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n","Collecting numpy (from torchvision)\n","  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp39-cp39-win_amd64.whl (15.8 MB)\n","     ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n","     ------------ --------------------------- 5.0/15.8 MB 27.4 MB/s eta 0:00:01\n","     ----------------------------------- --- 14.4/15.8 MB 36.3 MB/s eta 0:00:01\n","     --------------------------------------- 15.8/15.8 MB 35.6 MB/s eta 0:00:00\n","Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n","  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp39-cp39-win_amd64.whl (2.6 MB)\n","     ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n","     ---------------------------------------- 2.6/2.6 MB 30.2 MB/s eta 0:00:00\n","Collecting MarkupSafe>=2.0 (from jinja2->torch)\n","  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl (17 kB)\n","Collecting mpmath>=0.19 (from sympy->torch)\n","  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n","Installing collected packages: mpmath, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n","Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 pillow-10.2.0 sympy-1.12 torch-2.4.0+cu118 torchaudio-2.4.0+cu118 torchvision-0.19.0+cu118\n","Collecting scikit-image\n","  Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n","Requirement already satisfied: numpy>=1.23 in .\\.venv\\lib\\site-packages (from scikit-image) (1.26.3)\n","Collecting scipy>=1.9 (from scikit-image)\n","  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n","Requirement already satisfied: networkx>=2.8 in .\\.venv\\lib\\site-packages (from scikit-image) (3.2.1)\n","Requirement already satisfied: pillow>=9.1 in .\\.venv\\lib\\site-packages (from scikit-image) (10.2.0)\n","Collecting imageio>=2.33 (from scikit-image)\n","  Using cached imageio-2.35.0-py3-none-any.whl.metadata (5.0 kB)\n","Collecting tifffile>=2022.8.12 (from scikit-image)\n","  Using cached tifffile-2024.8.10-py3-none-any.whl.metadata (31 kB)\n","Requirement already satisfied: packaging>=21 in .\\.venv\\lib\\site-packages (from scikit-image) (24.1)\n","Collecting lazy-loader>=0.4 (from scikit-image)\n","  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n","Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl (12.9 MB)\n","   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n","   ---------------------------------------- 12.9/12.9 MB 81.0 MB/s eta 0:00:00\n","Using cached imageio-2.35.0-py3-none-any.whl (315 kB)\n","Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n","Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n","   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n","   ------------------- -------------------- 23.1/46.2 MB 112.3 MB/s eta 0:00:01\n","   ------------------------------------- -- 43.8/46.2 MB 107.2 MB/s eta 0:00:01\n","   ---------------------------------------- 46.2/46.2 MB 94.8 MB/s eta 0:00:00\n","Using cached tifffile-2024.8.10-py3-none-any.whl (225 kB)\n","Installing collected packages: tifffile, scipy, lazy-loader, imageio, scikit-image\n","Successfully installed imageio-2.35.0 lazy-loader-0.4 scikit-image-0.24.0 scipy-1.13.1 tifffile-2024.8.10\n","Collecting matplotlib\n","  Downloading matplotlib-3.9.2-cp39-cp39-win_amd64.whl.metadata (11 kB)\n","Collecting contourpy>=1.0.1 (from matplotlib)\n","  Downloading contourpy-1.2.1-cp39-cp39-win_amd64.whl.metadata (5.8 kB)\n","Collecting cycler>=0.10 (from matplotlib)\n","  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n","Collecting fonttools>=4.22.0 (from matplotlib)\n","  Downloading fonttools-4.53.1-cp39-cp39-win_amd64.whl.metadata (165 kB)\n","Collecting kiwisolver>=1.3.1 (from matplotlib)\n","  Downloading kiwisolver-1.4.5-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n","Requirement already satisfied: numpy>=1.23 in .\\.venv\\lib\\site-packages (from matplotlib) (1.26.3)\n","Requirement already satisfied: packaging>=20.0 in .\\.venv\\lib\\site-packages (from matplotlib) (24.1)\n","Requirement already satisfied: pillow>=8 in .\\.venv\\lib\\site-packages (from matplotlib) (10.2.0)\n","Collecting pyparsing>=2.3.1 (from matplotlib)\n","  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: python-dateutil>=2.7 in .\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n","Collecting importlib-resources>=3.2.0 (from matplotlib)\n","  Downloading importlib_resources-6.4.3-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: zipp>=3.1.0 in .\\.venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.0)\n","Requirement already satisfied: six>=1.5 in .\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Downloading matplotlib-3.9.2-cp39-cp39-win_amd64.whl (7.8 MB)\n","   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n","   ---------------------------------------- 7.8/7.8 MB 81.2 MB/s eta 0:00:00\n","Downloading contourpy-1.2.1-cp39-cp39-win_amd64.whl (182 kB)\n","Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n","Downloading fonttools-4.53.1-cp39-cp39-win_amd64.whl (2.2 MB)\n","   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n","   ---------------------------------------- 2.2/2.2 MB 129.5 MB/s eta 0:00:00\n","Downloading importlib_resources-6.4.3-py3-none-any.whl (35 kB)\n","Downloading kiwisolver-1.4.5-cp39-cp39-win_amd64.whl (56 kB)\n","Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n","Installing collected packages: pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n","Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.1 importlib-resources-6.4.3 kiwisolver-1.4.5 matplotlib-3.9.2 pyparsing-3.1.2\n","Collecting opencv-python\n","  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n","Requirement already satisfied: numpy>=1.17.0 in .\\.venv\\lib\\site-packages (from opencv-python) (1.26.3)\n","Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n","Installing collected packages: opencv-python\n","Successfully installed opencv-python-4.10.0.84\n","Requirement already satisfied: setuptools in .\\.venv\\lib\\site-packages (57.4.0)\n","Collecting transformers\n","  Using cached transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n","Requirement already satisfied: filelock in .\\.venv\\lib\\site-packages (from transformers) (3.13.1)\n","Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n","  Using cached huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.17 in .\\.venv\\lib\\site-packages (from transformers) (1.26.3)\n","Requirement already satisfied: packaging>=20.0 in .\\.venv\\lib\\site-packages (from transformers) (24.1)\n","Collecting pyyaml>=5.1 (from transformers)\n","  Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n","Requirement already satisfied: regex!=2019.12.17 in .\\.venv\\lib\\site-packages (from transformers) (2024.7.24)\n","Collecting requests (from transformers)\n","  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n","Collecting safetensors>=0.4.1 (from transformers)\n","  Downloading safetensors-0.4.4-cp39-none-win_amd64.whl.metadata (3.9 kB)\n","Collecting tokenizers<0.20,>=0.19 (from transformers)\n","  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl.metadata (6.9 kB)\n","Requirement already satisfied: tqdm>=4.27 in .\\.venv\\lib\\site-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in .\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in .\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Collecting charset-normalizer<4,>=2 (from requests->transformers)\n","  Downloading charset_normalizer-3.3.2-cp39-cp39-win_amd64.whl.metadata (34 kB)\n","Collecting idna<4,>=2.5 (from requests->transformers)\n","  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n","Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n","  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n","Collecting certifi>=2017.4.17 (from requests->transformers)\n","  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n","Using cached transformers-4.44.0-py3-none-any.whl (9.5 MB)\n","Using cached huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n","Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n","Downloading safetensors-0.4.4-cp39-none-win_amd64.whl (286 kB)\n","Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n","   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n","   ---------------------------------------- 2.2/2.2 MB 41.7 MB/s eta 0:00:00\n","Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n","Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n","Downloading charset_normalizer-3.3.2-cp39-cp39-win_amd64.whl (100 kB)\n","Using cached idna-3.7-py3-none-any.whl (66 kB)\n","Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n","Installing collected packages: urllib3, safetensors, pyyaml, idna, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n","Successfully installed certifi-2024.7.4 charset-normalizer-3.3.2 huggingface-hub-0.24.5 idna-3.7 pyyaml-6.0.2 requests-2.32.3 safetensors-0.4.4 tokenizers-0.19.1 transformers-4.44.0 urllib3-2.2.2\n","Collecting tensorflow\n","  Downloading tensorflow-2.17.0-cp39-cp39-win_amd64.whl.metadata (3.2 kB)\n","Collecting tensorflow-intel==2.17.0 (from tensorflow)\n","  Downloading tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl.metadata (5.0 kB)\n","Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n","Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n","  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n","Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n","  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n","Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n","  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n","Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading h5py-3.11.0-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n","Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n","Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading ml_dtypes-0.4.0-cp39-cp39-win_amd64.whl.metadata (20 kB)\n","Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n","  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: packaging in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading protobuf-4.25.4-cp39-cp39-win_amd64.whl.metadata (541 bytes)\n","Requirement already satisfied: requests<3,>=2.21.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (57.4.0)\n","Requirement already satisfied: six>=1.12.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n","Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: typing-extensions>=3.6.6 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n","Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading wrapt-1.16.0-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n","Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading grpcio-1.65.5-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n","Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n","  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n","Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Using cached keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.3)\n","Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow)\n","  Using cached wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting rich (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n","  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n","Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n","  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n","Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n","  Downloading optree-0.12.1-cp39-cp39-win_amd64.whl.metadata (48 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n","Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n","  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n","  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n","Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n","  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: importlib-metadata>=4.4 in .\\.venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (8.2.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in .\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n","Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n","  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in .\\.venv\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n","Requirement already satisfied: zipp>=0.5 in .\\.venv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.20.0)\n","Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n","  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n","Downloading tensorflow-2.17.0-cp39-cp39-win_amd64.whl (2.0 kB)\n","Downloading tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl (385.0 MB)\n","   ---------------------------------------- 0.0/385.0 MB ? eta -:--:--\n","   -- ------------------------------------ 20.2/385.0 MB 106.0 MB/s eta 0:00:04\n","   ---- ---------------------------------- 41.9/385.0 MB 106.6 MB/s eta 0:00:04\n","   ------ -------------------------------- 65.5/385.0 MB 109.9 MB/s eta 0:00:03\n","   -------- ------------------------------ 87.0/385.0 MB 108.9 MB/s eta 0:00:03\n","   ---------- --------------------------- 110.9/385.0 MB 110.6 MB/s eta 0:00:03\n","   ------------- ------------------------ 132.9/385.0 MB 110.3 MB/s eta 0:00:03\n","   --------------- ---------------------- 154.4/385.0 MB 109.6 MB/s eta 0:00:03\n","   ----------------- -------------------- 176.4/385.0 MB 109.4 MB/s eta 0:00:02\n","   ------------------- ------------------ 198.7/385.0 MB 109.5 MB/s eta 0:00:02\n","   --------------------- ---------------- 221.0/385.0 MB 109.5 MB/s eta 0:00:02\n","   ----------------------- -------------- 242.2/385.0 MB 109.0 MB/s eta 0:00:02\n","   -------------------------- ----------- 265.0/385.0 MB 110.3 MB/s eta 0:00:02\n","   ---------------------------- --------- 284.2/385.0 MB 108.1 MB/s eta 0:00:01\n","   ----------------------------- -------- 302.3/385.0 MB 107.4 MB/s eta 0:00:01\n","   ------------------------------- ------ 321.7/385.0 MB 106.1 MB/s eta 0:00:01\n","   --------------------------------- ---- 340.3/385.0 MB 103.4 MB/s eta 0:00:01\n","   ----------------------------------- -- 359.1/385.0 MB 102.2 MB/s eta 0:00:01\n","   -------------------------------------  379.1/385.0 MB 101.0 MB/s eta 0:00:01\n","   -------------------------------------  384.8/385.0 MB 100.4 MB/s eta 0:00:01\n","   -------------------------------------  384.8/385.0 MB 100.4 MB/s eta 0:00:01\n","   -------------------------------------  384.8/385.0 MB 100.4 MB/s eta 0:00:01\n","   -------------------------------------  384.8/385.0 MB 100.4 MB/s eta 0:00:01\n","   --------------------------------------- 385.0/385.0 MB 76.9 MB/s eta 0:00:00\n","Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n","Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n","Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n","Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Downloading grpcio-1.65.5-cp39-cp39-win_amd64.whl (4.1 MB)\n","   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n","   ---------------------------------------- 4.1/4.1 MB 61.7 MB/s eta 0:00:00\n","Downloading h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n","   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n","   ---------------------------------------- 3.0/3.0 MB 87.6 MB/s eta 0:00:00\n","Using cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n","Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n","Downloading ml_dtypes-0.4.0-cp39-cp39-win_amd64.whl (126 kB)\n","Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","Downloading protobuf-4.25.4-cp39-cp39-win_amd64.whl (413 kB)\n","Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n","Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n","   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n","   ---------------------------------------- 1.5/1.5 MB 76.5 MB/s eta 0:00:00\n","Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n","Downloading wrapt-1.16.0-cp39-cp39-win_amd64.whl (37 kB)\n","Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n","Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n","Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n","Using cached wheel-0.44.0-py3-none-any.whl (67 kB)\n","Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Downloading optree-0.12.1-cp39-cp39-win_amd64.whl (263 kB)\n","Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n","Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n","Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, h5py, grpcio, google-pasta, gast, absl-py, markdown-it-py, markdown, astunparse, tensorboard, rich, keras, tensorflow-intel, tensorflow\n","Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.65.5 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.4 rich-13.7.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0 werkzeug-3.0.3 wheel-0.44.0 wrapt-1.16.0\n","Collecting tf-keras\n","  Using cached tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: tensorflow<2.18,>=2.17 in .\\.venv\\lib\\site-packages (from tf-keras) (2.17.0)\n","Requirement already satisfied: tensorflow-intel==2.17.0 in .\\.venv\\lib\\site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.17.0)\n","Requirement already satisfied: absl-py>=1.0.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.3.0)\n","Requirement already satisfied: packaging in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (4.25.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.32.3)\n","Requirement already satisfied: setuptools in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (57.4.0)\n","Requirement already satisfied: six>=1.12.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.65.5)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.31.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.26.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in .\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.44.0)\n","Requirement already satisfied: rich in .\\.venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (13.7.1)\n","Requirement already satisfied: namex in .\\.venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.0.8)\n","Requirement already satisfied: optree in .\\.venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.12.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2024.7.4)\n","Requirement already satisfied: markdown>=2.6.8 in .\\.venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in .\\.venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in .\\.venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.3)\n","Requirement already satisfied: importlib-metadata>=4.4 in .\\.venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (8.2.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in .\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in .\\.venv\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in .\\.venv\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.18.0)\n","Requirement already satisfied: zipp>=0.5 in .\\.venv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.20.0)\n","Requirement already satisfied: mdurl~=0.1 in .\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.1.2)\n","Using cached tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\n","Installing collected packages: tf-keras\n","Successfully installed tf-keras-2.17.0\n","Name: transformers\n","Version: 4.44.0\n","Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n","Home-page: https://github.com/huggingface/transformers\n","Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n","Author-email: transformers@huggingface.co\n","License: Apache 2.0 License\n","Location: e:\\repos_kioxia\\win\\mgr\\emoroberta_repo\\.venv\\lib\\site-packages\n","Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n","Required-by: \n","Name: transformers\n","Version: 4.44.0\n","Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n","Home-page: https://github.com/huggingface/transformers\n","Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n","Author-email: transformers@huggingface.co\n","License: Apache 2.0 License\n","Location: e:\\repos_kioxia\\win\\mgr\\emoroberta_repo\\.venv\\lib\\site-packages\n","Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n","Required-by: \n"]}],"source":["# # ! python -m pip install --upgrade pip\n","# ! pip install ftfy regex tqdm\n","# # ! pip install git+https://github.com/openai/CLIP.git\n","\n","# ! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","# # ! pip install --upgrade --force-reinstall torch==2.2.1 torchvision==0.17.1 torchaudio==2.2.1\n","# # (use --upgrade --force-reinstall to upgrade)\n","\n","# ! pip install scikit-image\n","# ! pip install matplotlib\n","# ! pip install opencv-python\n","# ! pip install setuptools\n","# # ! pip install --upgrade --force-reinstall transformers==4.36.0\n","# ! pip install transformers\n","# ! pip install tensorflow\n","# ! pip install tf-keras\n","# ! pip show transformers\n","# ! pip show transformers\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["import os\n","import skimage\n","import IPython.display\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import json\n","\n","from collections import OrderedDict\n","import torch\n","import torch.nn as nn\n","\n","import tensorflow as tf\n","\n","from sklearn.model_selection import train_test_split\n","\n","from pkg_resources import packaging\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Torch version: 2.4.0+cu118\n","True\n","CUDA version: 11.8\n"]}],"source":["import numpy as np\n","import torch\n","from pkg_resources import packaging\n","\n","print(\"Torch version:\", torch.__version__)\n","print(torch. cuda. is_available())\n","print(\"CUDA version:\", torch.version.cuda)"]},{"cell_type":"markdown","metadata":{},"source":["# Loading the model"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["e:\\repos_kioxia\\win\\mgr\\emoroberta_repo\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From e:\\repos_kioxia\\win\\mgr\\emoroberta_repo\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]},{"name":"stderr","output_type":"stream","text":["e:\\repos_kioxia\\win\\mgr\\emoroberta_repo\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From e:\\repos_kioxia\\win\\mgr\\emoroberta_repo\\.venv\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"]},{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n","\n","All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"]}],"source":["# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n","# # model = AutoModelForSequenceClassification.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n","# model = AutoModelForSequenceClassification.from_pretrained(\"arpanghoshal/EmoRoBERTa\", from_tf=True)\n","\n","from transformers import RobertaTokenizerFast, TFRobertaForSequenceClassification, pipeline\n","\n","tokenizer = RobertaTokenizerFast.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n","model = TFRobertaForSequenceClassification.from_pretrained(\"arpanghoshal/EmoRoBERTa\")"]},{"cell_type":"markdown","metadata":{},"source":["### Load in pipeline"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["401 Client Error. (Request ID: Root=1-66c2789a-111f5628716a9b8a142cb734;8186a7b4-e90f-4ee0-bb4a-8c4e3a60bd48)\n","\n","Cannot access gated repo for url https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/tf_model.h5.\n","Access to model arpanghoshal/EmoRoBERTa is restricted. You must be authenticated to access it.\n","All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n","\n","All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n","e:\\repos_kioxia\\win\\mgr\\emoroberta_repo\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"]},{"name":"stdout","output_type":"stream","text":["[{'label': 'gratitude', 'score': 0.9964383840560913}]\n"]}],"source":["emotion = pipeline('sentiment-analysis', \n","                    model='arpanghoshal/EmoRoBERTa')\n","\n","emotion_labels = emotion(\"Thanks for using it.\")\n","print(emotion_labels)"]},{"cell_type":"markdown","metadata":{},"source":["### Load directly"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'label': 'gratitude', 'score': 0.9964383840560913}]\n"]}],"source":["text = \"Hello, my dog is cute\"\n","inputs = tokenizer(text, return_tensors=\"pt\")\n","# convert inputs to tensorflow\n","inputs = {name: tf.convert_to_tensor(tensor) for name, tensor in inputs.items()}\n","\n","with torch.no_grad():\n","    logits = model(inputs).logits\n","\n","# torch\n","# predicted_class_id = logits.argmax().item()\n","# model.config.id2label[predicted_class_id]\n","\n","# tf\n","predicted_class_id = tf.argmax(logits, axis=1).numpy()[0]\n","model.config.id2label[predicted_class_id]\n","\n","print(emotion_labels)"]},{"cell_type":"markdown","metadata":{},"source":["Prepare data"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'json' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Subtask_2_train.json\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     text_data_list \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# text data is a map of conversation id to conversation\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     text_data \u001b[38;5;241m=\u001b[39m {text[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconversation_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]: text \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m text_data_list}\n","\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"]}],"source":["with open('data/Subtask_2_train.json') as f:\n","    text_data_list = json.load(f)\n","    # text data is a map of conversation id to conversation\n","    text_data = {text['conversation_ID']: text for text in text_data_list}\n","\n","# list of video filenames\n","texts = []\n","video_fnames_list = []\n","n_utts = 0\n","labels = []\n","\n","for c_id, conv in text_data.items():\n","    n_utts += len(conv['conversation'])\n","    for utt in conv['conversation']:\n","        # u_id = utt['utterance_ID']\n","        texts.append(utt['text'])\n","        labels.append(utt['emotion'])\n","        video_fnames_list.append(utt['video_name'])\n","\n","print(len(video_fnames_list), n_utts)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(texts[:3])\n","print(labels[:3])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### Old split method - splitting features directly\n","\n","# X_train, X_test, Y_train, Y_test = train_test_split(X.cpu().numpy(), Y.cpu().numpy(), test_size=0.2, random_state=42)\n","\n","# X_train = torch.tensor(X_train).cuda()\n","# X_test = torch.tensor(X_test).cuda()\n","# Y_train = torch.tensor(Y_train).cuda()\n","# Y_test = torch.tensor(Y_test).cuda()\n","\n","# print(X_train.shape, Y_train.shape)\n","# print(X_test.shape, Y_test.shape)\n","\n","# class_counts = Y_train.sum(dim=0)\n","# class_counts\n","\n","###################################################\n","\n","### New split method - splitting indices\n","\n","train_indices, test_indices = train_test_split(range(len(video_fnames_list)), test_size=0.2, random_state=42)\n","\n","# lengths\n","print(len(train_indices), len(test_indices))\n","\n","# create a list of video filenames, X_train, X_test, Y_train, Y_test\n","\n","train_video_fnames = [video_fnames_list[i] for i in train_indices]\n","test_video_fnames = [video_fnames_list[i] for i in test_indices]\n","\n","# split texts and labels by indices\n","train_texts = [texts[i] for i in train_indices]\n","test_texts = [texts[i] for i in test_indices]\n","\n","train_labels = [labels[i] for i in train_indices]\n","test_labels = [labels[i] for i in test_indices]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Prepare encodings and labels for classification"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["9966\n"]}],"source":["text_data_filtered = text_data.copy()\n","for c_id, conv in text_data.items():\n","    text_data_filtered[c_id]['conversation'] = [utt for utt in conv['conversation'] if (c_id, utt['utterance_ID']) not in missing_encodings[frame_types[4]]]\n","\n","n_utts = 0\n","labels = []\n","for c_id, conv in text_data_filtered.items():\n","    n_utts += len(conv['conversation'])\n","    labels += [utt['emotion'] for utt in conv['conversation']]\n","\n","print(len(labels))"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["neutral     4389\n","joy         1708\n","surprise    1365\n","anger       1140\n","sadness      789\n","disgust      301\n","fear         274\n","Name: count, dtype: int64"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","pd.Series(labels).value_counts()"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder\n","import numpy as np\n","\n","onehot_encoder = OneHotEncoder()\n","Y = onehot_encoder.fit_transform(np.array(labels).reshape(-1, 1))\n","Y = torch.tensor(Y.toarray()).cuda()"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([9966, 1024])"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["frame_type = frame_types[4]\n","path = f'./data/features/{frame_type}'\n","image_features = torch.load(f'{path}/image_features.pt')\n","text_features = torch.load(f'{path}/text_features.pt')\n","\n","X = torch.cat((image_features, text_features), dim=1)\n","X.shape"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"]}],"source":["print(torch.isnan(X).sum(), torch.isnan(Y).sum())"]},{"cell_type":"markdown","metadata":{},"source":["## Classification"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb","timestamp":1712072239943}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
