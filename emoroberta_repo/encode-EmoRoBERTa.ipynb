{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Attempt at classification using EmoRoBERTa (using legacy Python 3.9.7)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104403,"status":"ok","timestamp":1712153718400,"user":{"displayName":"Alex Terentowicz","userId":"10722644937446686009"},"user_tz":-120},"id":"0BpdJkdBssk9","outputId":"cf422b63-9319-44e7-9f42-fde2450a3bac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting scikit-learn\n","  Downloading scikit_learn-1.5.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n","Requirement already satisfied: numpy>=1.19.5 in .\\.venv\\lib\\site-packages (from scikit-learn) (1.26.3)\n","Requirement already satisfied: scipy>=1.6.0 in .\\.venv\\lib\\site-packages (from scikit-learn) (1.13.1)\n","Collecting joblib>=1.2.0 (from scikit-learn)\n","  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n","Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n","  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n","Downloading scikit_learn-1.5.1-cp39-cp39-win_amd64.whl (11.0 MB)\n","   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n","   ---------------------------------------- 11.0/11.0 MB 68.8 MB/s eta 0:00:00\n","Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n","Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n","Installing collected packages: threadpoolctl, joblib, scikit-learn\n","Successfully installed joblib-1.4.2 scikit-learn-1.5.1 threadpoolctl-3.5.0\n"]}],"source":["# # ! python -m pip install --upgrade pip\n","# ! pip install ftfy regex tqdm\n","# # ! pip install git+https://github.com/openai/CLIP.git\n","\n","# ! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","# # ! pip install --upgrade --force-reinstall torch==2.2.1 torchvision==0.17.1 torchaudio==2.2.1\n","# # (use --upgrade --force-reinstall to upgrade)\n","\n","# ! pip install scikit-image\n","# ! pip install matplotlib\n","# ! pip install opencv-python\n","# ! pip install setuptools\n","# # ! pip install --upgrade --force-reinstall transformers==4.36.0\n","# ! pip install transformers\n","# ! pip install tensorflow\n","# ! pip install tf-keras\n","! pip install scikit-learn\n","# ! pip show transformers\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import skimage\n","import IPython.display\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import json\n","\n","from collections import OrderedDict\n","import torch\n","import torch.nn as nn\n","\n","import tensorflow as tf\n","\n","from sklearn.model_selection import train_test_split\n","\n","from pkg_resources import packaging\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Torch version: 2.4.0+cu118\n","True\n","CUDA version: 11.8\n"]}],"source":["import numpy as np\n","import torch\n","from pkg_resources import packaging\n","\n","print(\"Torch version:\", torch.__version__)\n","print(torch. cuda. is_available())\n","print(\"CUDA version:\", torch.version.cuda)"]},{"cell_type":"markdown","metadata":{},"source":["# Loading the model"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["e:\\repos_kioxia\\win\\mgr\\emoroberta_repo\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From e:\\repos_kioxia\\win\\mgr\\emoroberta_repo\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]},{"name":"stderr","output_type":"stream","text":["e:\\repos_kioxia\\win\\mgr\\emoroberta_repo\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From e:\\repos_kioxia\\win\\mgr\\emoroberta_repo\\.venv\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"]},{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n","\n","All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"]}],"source":["from transformers import RobertaTokenizerFast, TFRobertaForSequenceClassification, pipeline\n","\n","tokenizer = RobertaTokenizerFast.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n","model = TFRobertaForSequenceClassification.from_pretrained(\"arpanghoshal/EmoRoBERTa\")"]},{"cell_type":"markdown","metadata":{},"source":["### Predict using pipeline"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["401 Client Error. (Request ID: Root=1-66c44c19-75f9a19160c48daf3ed6f4eb;7bcf956f-183b-4375-abe6-2adc25d43d6e)\n","\n","Cannot access gated repo for url https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/tf_model.h5.\n","Access to model arpanghoshal/EmoRoBERTa is restricted. You must be authenticated to access it.\n","All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n","\n","All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n","Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"]},{"name":"stdout","output_type":"stream","text":["[{'label': 'gratitude', 'score': 0.9964383840560913}]\n"]}],"source":["emotion = pipeline('sentiment-analysis', \n","                    model='arpanghoshal/EmoRoBERTa')\n","\n","emotion_labels = emotion(\"Thanks for using it.\")\n","print(emotion_labels)"]},{"cell_type":"markdown","metadata":{},"source":["### Predict locally"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["[{'label': 'gratitude', 'score': 0.9964383840560913}]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["def predict_emotion(text):\n","    inputs = tokenizer(text, return_tensors=\"pt\")\n","    # convert inputs to tensorflow\n","    inputs = {name: tf.convert_to_tensor(tensor) for name, tensor in inputs.items()}\n","\n","    with torch.no_grad():\n","        logits = model(inputs).logits\n","\n","    # torch\n","    # predicted_class_id = logits.argmax().item()\n","    # model.config.id2label[predicted_class_id]\n","\n","    # tf\n","    predicted_class_id = tf.argmax(logits, axis=1).numpy()[0]\n","    model.config.id2label[predicted_class_id]\n","\n","    return emotion_labels\n","\n","\n","\n","text = \"Hello, my dog is cute\"\n","predict_emotion(text)"]},{"cell_type":"markdown","metadata":{},"source":["# Prepare data"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["13619 13619\n"]}],"source":["with open('data/Subtask_2_train.json') as f:\n","    text_data_list = json.load(f)\n","    # text data is a map of conversation id to conversation\n","    text_data = {text['conversation_ID']: text for text in text_data_list}\n","\n","# list of video filenames\n","texts = []\n","video_fnames_list = []\n","n_utts = 0\n","labels = []\n","\n","for c_id, conv in text_data.items():\n","    n_utts += len(conv['conversation'])\n","    for utt in conv['conversation']:\n","        # u_id = utt['utterance_ID']\n","        texts.append(utt['text'])\n","        labels.append(utt['emotion'])\n","        video_fnames_list.append(utt['video_name'])\n","\n","print(len(video_fnames_list), n_utts)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['Alright , so I am back in high school , I am standing in the middle of the cafeteria , and I realize I am totally naked .', 'Oh , yeah . Had that dream .', 'Then I look down , and I realize there is a phone ... there .']\n","['neutral', 'neutral', 'surprise']\n"]}],"source":["print(texts[:3])\n","print(labels[:3])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["10895 2724\n"]}],"source":["### Old split method - splitting features directly\n","\n","# X_train, X_test, Y_train, Y_test = train_test_split(X.cpu().numpy(), Y.cpu().numpy(), test_size=0.2, random_state=42)\n","\n","# X_train = torch.tensor(X_train).cuda()\n","# X_test = torch.tensor(X_test).cuda()\n","# Y_train = torch.tensor(Y_train).cuda()\n","# Y_test = torch.tensor(Y_test).cuda()\n","\n","# print(X_train.shape, Y_train.shape)\n","# print(X_test.shape, Y_test.shape)\n","\n","# class_counts = Y_train.sum(dim=0)\n","# class_counts\n","\n","###################################################\n","\n","### New split method - splitting indices\n","\n","train_indices, test_indices = train_test_split(range(len(video_fnames_list)), test_size=0.2, random_state=42)\n","\n","# lengths\n","print(len(train_indices), len(test_indices))\n","\n","# create a list of video filenames, X_train, X_test, Y_train, Y_test\n","\n","train_video_fnames = [video_fnames_list[i] for i in train_indices]\n","test_video_fnames = [video_fnames_list[i] for i in test_indices]\n","\n","# split texts and labels by indices\n","train_texts = [texts[i] for i in train_indices]\n","test_texts = [texts[i] for i in test_indices]\n","\n","train_labels = [labels[i] for i in train_indices]\n","test_labels = [labels[i] for i in test_indices]"]},{"cell_type":"markdown","metadata":{},"source":["# Classify\n","## Zero-shot classification"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['gratitude', 'gratitude', 'gratitude', 'gratitude', 'gratitude']\n"]}],"source":["test_predicted_labels = []\n","\n","for i, text in enumerate(test_texts):\n","    prediction = predict_emotion(text)\n","    predicted_emotion = prediction[0]['label']\n","    test_predicted_labels.append(predicted_emotion)\n","\n","print(test_predicted_labels[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(set(test_predicted_labels))\n","print(set(test_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","plt.rc('figure', figsize=(9, 5))\n","\n","labels_ordered = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n","\n","cm = confusion_matrix(test_labels, test_predicted_labels, labels=labels_ordered)\n","plt.figure()\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels_ordered, yticklabels=labels_ordered)\n","plt.savefig(f'./experiments/plots/EkmanClassifier/confusion_matrix.png')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Fine-tuning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# encode\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n","test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n","\n","# convert to tensors\n","train_dataset = tf.data.Dataset.from_tensor_slices((\n","    dict(train_encodings),\n","    train_labels\n","))\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((\n","    dict(test_encodings),\n","    test_labels\n","))\n","\n","# shuffle and batch\n","train_dataset = train_dataset.shuffle(100).batch(16)\n","test_dataset = test_dataset.batch(16)\n","\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# train\n","model.compile(optimizer='adam',\n","                loss=loss,\n","                metrics=['accuracy'])\n","model.fit(train_dataset, epochs=2)\n","\n","# evaluate\n","model.evaluate(test_dataset)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb","timestamp":1712072239943}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
